{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQVQc0XRhkXp"
      },
      "source": [
        "### Setup the software"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FPEx4U0wezNX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to set everything up. This can take several minutes.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install() \n",
        "!git clone https://github.com/Dan-Burns/molecular_dynamics_analysis_tools.git &> /dev/null\n",
        "\n",
        "\n",
        "#1. Install OpenMM and core dependencies\n",
        "print(\"Installing Python packages.\")\n",
        "!conda install -c conda-forge openmm=8.0.0 pdbfixer mdtraj biopython py3dmol numpy pandas matplotlib &> /dev/null\n",
        "# too much in the yml - broke after colab updated to python 3.10 \n",
        "#!conda env update --file molecular_dynamics_analysis_tools/seq_to_ensemble_environment.yml --prune &> /dev/null\n",
        "#2. Download openawsem\n",
        "print(\"Installing OpenAwsem\")\n",
        "!git clone https://github.com/PotoyanGroup/openawsem &> /dev/null\n",
        "\n",
        "#3. Download pdb_seqres\n",
        "!wget ftp://ftp.wwpdb.org/pub/pdb/derived_data/pdb_seqres.txt &> /dev/null\n",
        "!mv pdb_seqres.txt openawsem/ &> /dev/null\n",
        "\n",
        "#4. Download and isntall stride\n",
        "!wget http://webclu.bio.wzw.tum.de/stride/stride.tar.gz &> /dev/null\n",
        "!mkdir stride_loc && tar -xf stride.tar.gz -C ./stride_loc &> /dev/null\n",
        "!cd stride_loc && make &> /dev/null\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftXm1usFt7lK"
      },
      "source": [
        "### Create Project and Run simulation\n",
        "\n",
        "Upload a PDB file of protein which can be obtained either via AlphaFold or from PDB database. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yop0UegFlWAB"
      },
      "outputs": [],
      "source": [
        "#@title Upload a PDB file\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  os.rename(fn, 'input.pdb')\n",
        "\n",
        "# Create project "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7IoT3eYIblH6"
      },
      "outputs": [],
      "source": [
        "#@title Run Molecular Dynamics with the [AWSEM](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008308) Coarse-Grained Force-Field for Proteins \n",
        "Temperature = 250.0 #@param {type:\"number\"}\n",
        "Timesteps   = 50000 #@param {type:\"number\"}\n",
        "\n",
        "!export OPENAWSEM_LOCATION=/content/openawsem/ && PATH={$PATH}:/content/stride_loc && python3 /content/openawsem/mm_create_project.py input.pdb\n",
        "!cp input-openmmawsem.pdb template.pdb\n",
        "!export OPENAWSEM_LOCATION=/content/openawsem/ && python3 ./openawsem/helperFunctions/convertOpenmmTrajectoryToStandardMovie.py template.pdb\n",
        "\n",
        "!export OPENAWSEM_LOCATION=/content/openawsem/ && python3 mm_run.py input  --steps $Timesteps --tempStart $Temperature --tempEnd $Temperature -f forces_setup.py -p CUDA -r 1000 \n",
        "\n",
        "#@markdown ---\n",
        "#@markdown > Lu, Wei, et al. \"OpenAWSEM with Open3SPN2: A fast, flexible, and accessible framework for large-scale coarse-grained biomolecular simulations.\" <em>PLoS computational biology 17.2 (2021): e1008308 </em>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "claXqoq4_HTX"
      },
      "outputs": [],
      "source": [
        "#@title Install Analysis Tools\n",
        "%%capture\n",
        "# should probably send all the shell commands to /dev/null so the user\n",
        "# can get updated on what's going on with print statements.\n",
        "!pip install MDAnalysis\n",
        "!git clone https://github.com/Dan-Burns/molecular_dynamics_analysis_tools.git\n",
        "!pip install paramagpy # not using atm\n",
        "!pip install biopandas\n",
        "!pip install scipy\n",
        "!pip install parmed\n",
        "from molecular_dynamics_analysis_tools.rdcs import *\n",
        "from molecular_dynamics_analysis_tools.rdcs_least_squares import *\n",
        "from molecular_dynamics_analysis_tools.useful_functions import identical_subunits\n",
        "#### for rebuilding sidechains from CG structures\n",
        "#https://download.igb.uci.edu/sidepro_readme.txt\n",
        "# this is the main delay on this install cell\n",
        "!wget https://download.igb.uci.edu/sidepro.linux.tar.gz\n",
        "!tar xvf sidepro.linux.tar.gz\n",
        "!conda install -c conda-forge pdbfixer\n",
        "# for protonating structures after sidechains are added\n",
        "!pip install pdb2pqr\n",
        "# for minimizing the sidechains\n",
        "from molecular_dynamics_analysis_tools.minimize import minimize_sidechains\n",
        "####\n",
        "# might need this because using wget can throw an error randomly\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "###\n",
        "\n",
        "import py3Dmol\n",
        "from sklearn.decomposition import PCA\n",
        "import mdtraj as md\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dSLREcYwACYm"
      },
      "outputs": [],
      "source": [
        "## Silence errors/warnings\n",
        "#%%capture\n",
        "\n",
        "#@title ##Perform RMSD Clustering of the Trajectory to Generate Conformational Ensembles\n",
        "from Bio.PDB import PDBParser\n",
        "import MDAnalysis.analysis.encore as encore\n",
        "import MDAnalysis as mda\n",
        "from MDAnalysis.analysis import align\n",
        "\n",
        "#@markdown Set Maximum Number of Clusters to Generate. \n",
        "#@markdown This will produce n ensembles composed of 1 to n structures.\n",
        "#@markdown Subsequent RDC fitting will reveal the best ensemble among these.\n",
        "n_clusters = 5 #@param {type:\"number\"}\n",
        "# link to library?\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pdb   = 'template.pdb'\n",
        "model = PDBParser().get_structure('structure',pdb) \n",
        "\n",
        "# hold chain IDs and residue object lists\n",
        "# use to compare the subunits and figure out if they're identical or not\n",
        "chains = {chain.id: chain.get_unpacked_list() for chain in model.get_chains()}\n",
        "\n",
        "trajectory = 'movie.dcd'\n",
        "structure = 'template.pdb'\n",
        "u = mda.Universe(structure, trajectory)\n",
        "\n",
        "#############################\n",
        "# if it's a homo-multimer, separate the subunits and concatenate into\n",
        "# a long single-subunit trajectory for clustering\n",
        "# Otherwise deal with the trajectory and one or more subunits in its original form\n",
        "if identical_subunits(chains) == True: \n",
        "  # make a dictionary of chain/subunit keys with atom selection values\n",
        "  selections = {}\n",
        "  for chain in chains.keys():\n",
        "    selections[chain] = u.select_atoms('segid '+chain)\n",
        "\n",
        "  # make a directory to hold the seperated subunits\n",
        "  out_dir = 'seperated_trajectories/'\n",
        "  if not os.path.exists(out_dir):\n",
        "      os.makedirs(out_dir)\n",
        "  # clean the directory if it already exists\n",
        "  for f in os.listdir(out_dir):\n",
        "      os.remove(out_dir+f)\n",
        "\n",
        "  # Instead of writing the seperated trajectories to files, \n",
        "  # can probably use u.merge() - but people might want to download trajectories...\n",
        "  for chain, selection in selections.items():\n",
        "      with mda.Writer(f'{out_dir}chain_{chain}.dcd', selection.n_atoms) as W:\n",
        "          for ts in u.trajectory:\n",
        "              W.write(selection)\n",
        "  # write one subunit to a pdb\n",
        "  # can probably just use the selection instead of a saved pdb\n",
        "  # assuming we're just working with EI dimer for this\n",
        "  selections[list(selections.keys())[0]].write('one_subunit.pdb')\n",
        " \n",
        "  # align the seperated subunit trajectory\n",
        "  # conatenate\n",
        "  seperated_trajs = [out_dir+traj for traj in os.listdir(out_dir) if traj.endswith('dcd')]\n",
        "  pdb = 'one_subunit.pdb'\n",
        "  ref = mda.Universe(pdb)\n",
        "  sep_u = mda.Universe(pdb, seperated_trajs)\n",
        "  aligned_traj_name = 'aligned_seperated_subunits.dcd'\n",
        "  print('Aligning trajectory.')\n",
        "  align.AlignTraj(sep_u, ref,select='name CA',filename=aligned_traj_name).run()\n",
        "\n",
        "\n",
        "else: ## just align the original trajectory for clustering \n",
        "  from MDAnalysis.analysis import align\n",
        "  print('Aligning trajectory.')\n",
        "  aligned_traj_name = 'aligned_traj.dcd'\n",
        "  ref = mda.Universe(pdb)\n",
        "  align.AlignTraj(u, ref, select='name CA',filename=aligned_traj_name).run()\n",
        "\n",
        "for cluster_iteration in range(n_clusters):\n",
        "    print(f\"Cluster iteration {cluster_iteration+1}\")\n",
        "    structure = pdb\n",
        "    trajectory = aligned_traj_name\n",
        "    u = mda.Universe(structure, trajectory)\n",
        "    # add n_jobs argument so that all n_init are run in parallel (default is 10)\n",
        "    ensemble = encore.cluster(u, method=encore.clustering.ClusteringMethod.KMeans(n_clusters=cluster_iteration+1))\n",
        "    #####################################\n",
        "    # change this selection from 'name CA' to 'protein' when using structure file with \n",
        "    # correct residue names\n",
        "    #####################################\n",
        "    selection = u.select_atoms('protein')\n",
        "    ######################################\n",
        "    clusters = []\n",
        "    for i, cluster in enumerate(ensemble.clusters):\n",
        "        u.trajectory[cluster.centroid]\n",
        "        if not os.path.exists(f'cluster_{cluster_iteration+1}/'):\n",
        "          os.makedirs(f'cluster_{cluster_iteration+1}/')\n",
        "        selection.write(f'cluster_{cluster_iteration+1}/centroid_{i+1}.pdb')\n",
        "        clusters.append(int(cluster.centroid))\n",
        "\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXu7nzFUuUz2"
      },
      "outputs": [],
      "source": [
        "#@title Least Squares Fitting of RDCs to Ensembles\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "# Add Egner/Venditti Reference?\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "uploaded_rdcs = files.upload()\n",
        "\n",
        "for fn in uploaded_rdcs.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded_rdcs[fn])))\n",
        "  os.rename(fn, 'rdcs.dat')\n",
        "#@markdown Upload your RDC file\n",
        "\n",
        "rdc_file = 'rdcs.dat'\n",
        "# set up folders\n",
        "rdc_results = 'rdc_fitting_results'\n",
        "params_folder = f'{rdc_results}/par'\n",
        "if os.path.exists(rdc_results):\n",
        "  pass\n",
        "else:\n",
        "  os.makedirs(rdc_results)\n",
        "if os.path.exists(params_folder):\n",
        "  pass\n",
        "else:\n",
        "  os.makedirs(params_folder)\n",
        "\n",
        "\n",
        "# make a list of the folders that contain the cluster iteration centroids\n",
        "# will have to change the list comprehension if we add option to do specific cluster iterations\n",
        "cluster_folders = [f'cluster_{i+1}' for i in range(n_clusters)]\n",
        "fig, axs = plt.subplots(n_clusters,1,\n",
        "                        sharex=True,sharey=True,\n",
        "                        figsize=(8,n_clusters*8))\n",
        "# save the backcalculated RDCs and R values\n",
        "rdc_dictionary = {}\n",
        "rdc_R_values = {}\n",
        "final_pars = {}\n",
        "for i, pdb_folder in enumerate(cluster_folders):\n",
        "  #### maybe use average par from last fit to start the next one\n",
        "  print(f'Performing fit on ensemble {i+1}')\n",
        "  # Fit happens inside this class and all the results are available\n",
        "  # in the attributes\n",
        "  fit = FitRDCs(pdb_folder,rdc_file)\n",
        "  fit.fit_rdcs()\n",
        "\n",
        "  # save back calculated rdcs and R\n",
        "  rdc_dictionary[f'{i+1}_member_ensemble'] = fit.fitted_rdcs\n",
        "  rdc_R_values[f'{i+1}_member_ensemble'] = round(fit.Rfactor,4)\n",
        "  #parameters\n",
        "  if i == 0:\n",
        "    params = pd.DataFrame(fit.jac.x[np.newaxis,:],columns=['angle_a(rad)','angle_b(rad)','angle_c(rad)','Azz','r'],\n",
        "               index=[f'centroid_{i+1}'])\n",
        "    params.to_csv(f'{params_folder}/{i+1}_member_ensemble_params.csv')\n",
        "  else:\n",
        "    params = pd.DataFrame(fit.jac.x.reshape(-1,5),\n",
        "               columns=['angle_a(rad)','angle_b(rad)','angle_c(rad)','Azz','r'],\n",
        "               index=[f'centroid_{j+1}' for j in range(i+1)])\n",
        "    params.to_csv(f'{params_folder}/{i+1}_member_ensemble_params.csv')\n",
        "\n",
        "  # plot\n",
        "  axs.flat[i].plot(fit.rdc_values, fit.fitted_rdcs, marker='o', lw=0, ms=2, c='r',\n",
        "          label=f'R = {round(fit.Rfactor,4)}')\n",
        "\n",
        "  # plot the diagonal\n",
        "  l, h = axs.flat[i].get_xlim()\n",
        "  axs.flat[i].plot([l,h],[l,h],'-k', zorder=0, ms=2)\n",
        "  axs.flat[i].set_xlim(l,h)\n",
        "  axs.flat[i].set_ylim(l,h)\n",
        "\n",
        "  # labels\n",
        "  axs.flat[i].set_xlabel(\"Experimental RDCs\")\n",
        "  axs.flat[i].set_ylabel(f\"{i+1} Member Ensemble RDCs\")\n",
        "  axs.flat[i].legend()\n",
        "fig.savefig(f'{rdc_results}/rdc_plots.pdf')\n",
        "\n",
        "rdc_df = pd.DataFrame(rdc_dictionary,index=fit.residue_ids)\n",
        "rdc_df.to_csv(f'{rdc_results}/ensemble_rdcs.csv')\n",
        "rdc_R_df = pd.DataFrame(rdc_R_values,index=['R'])\n",
        "rdc_R_df.to_csv(f'{rdc_results}/ensemble_R_values.csv')\n",
        "\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gqenuSbNI-fC"
      },
      "outputs": [],
      "source": [
        "#@title Zip and Download the Results\n",
        "#@markdown If the results archive does not download automatically (possibly due to an adblocker), click on the little folder icon to the left, navigate to the `seq_to_ensemble_output.zip` file, right-click (or click on the adjacent three dots) and select \\\"Download\\\".\n",
        "# add sidechains back to the coarse grained centroid structures\n",
        "print(\"Please wait a few moments while the protein sidechains are rebuilt on the coarse grained structures.\\n\\\n",
        "        See Nagata, K., Randall, A. & Baldi, P. SIDEpro: a novel machine learning approach for the fast and accurate prediction of side-chain conformations.\\n\\\n",
        "         Proteins 80, 142â€“153 (2012).\")\n",
        "print(\"After modelling the sidechains, the structures will be protonated at pH 7 with pdb2pqr.\\n\\\n",
        "\\t https://pdb2pqr.readthedocs.io/en/latest/supporting.html\")\n",
        "\n",
        "        \n",
        "from pdbfixer import PDBFixer\n",
        "from openmm.app import PDBFile\n",
        "\n",
        "cluster_folders = [f'cluster_{i+1}' for i in range(n_clusters)]\n",
        "# just enumerating this to track progress\n",
        "for count, cluster_folder in enumerate(cluster_folders):\n",
        "  print(f'Rebuilding sidechains for ensemble {count+1}',flush=True)\n",
        "  #make a new folder to hold the structures with sidechains\n",
        "  if os.path.exists(f'all_atom_{cluster_folder}'):\n",
        "    pass\n",
        "  else:\n",
        "    os.makedirs(f'all_atom_{cluster_folder}')\n",
        "  for pdb_index, cg_pdb in enumerate([f'{cluster_folder}/centroid_{i+1}.pdb' \n",
        "                         for i in range(len(os.listdir(cluster_folder)))]):\n",
        "    fixer = PDBFixer(filename=cg_pdb)\n",
        "    fixer.findMissingResidues()\n",
        "    fixer.findMissingAtoms()\n",
        "    ### TODO this will need to account for multi-chain structures, right now it's assuming there is just one \n",
        "    # chain with terminals that need to be fixed\n",
        "    # get the first and last residues of a single chain\n",
        "    first, last = list(fixer.missingAtoms.keys())[0], list(fixer.missingAtoms.keys())[-1]\n",
        "    # new dictionary with only the terminal N and C atoms \n",
        "    # this is because sidepro needs all of the backbone atoms, otherwise the terminal residues will be deleted\n",
        "    to_fix = {first:[atom for atom in fixer.missingAtoms[first] if atom.name=='N'], \n",
        "              last:[atom for atom in fixer.missingAtoms[last] if atom.name=='C']} \n",
        "    fixer.missingAtoms = to_fix\n",
        "    # add the missing terminal N and C atoms\n",
        "    fixer.addMissingAtoms()\n",
        "    # just hold the fixed terminal residue pdb and delete after conversion\n",
        "    PDBFile.writeFile(fixer.topology, fixer.positions, open('temp.pdb', 'w'))\n",
        "    # add sidechains\n",
        "    # sidepro2.0 is super fast, pdbfixer takes too long to add all of the sidechains (2+ minutes - can't do this for dozens of structures)\n",
        "    # sending to /dev/null since this produces a ton of output\n",
        "    !cd SIDEpro2.0/; ./SIDEpro -i ../temp.pdb -f ../cleaned_pdbs/input.pdb -o ../all_atom_{cluster_folder}/sc_centroid_{pdb_index +1}.pdb &> /dev/null\n",
        "    # protonate at pH 7, 300K\n",
        "    !pdb2pqr --ff AMBER all_atom_{cluster_folder}/sc_centroid_{pdb_index +1}.pdb all_atom_{cluster_folder}/aa_centroid_{pdb_index +1}.pdb &> /dev/null\n",
        "    # remove the intermediate structure files\n",
        "    !rm all_atom_{cluster_folder}/sc_centroid_{pdb_index +1}.pdb\n",
        "    # delete the pdb2pqr log file\n",
        "    !rm all_atom_{cluster_folder}/aa_centroid_{pdb_index +1}.log\n",
        "    !rm temp.pdb\n",
        "print('Zipping everything up.')\n",
        "!zip -FSr \"seq_to_ensemble_output.zip\" all_atom_cluster_* rdc_fitting_results &> /dev/null\n",
        "files.download(\"seq_to_ensemble_output.zip\")\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vygcsKpagu0-"
      },
      "source": [
        "OPTIONAL Side Chain Minimization of Ensembles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1vHbChMPHvNa"
      },
      "outputs": [],
      "source": [
        "#@title What are the best ensembles?\n",
        "## TODO plot R values vs ensemble size\n",
        "from molecular_dynamics_analysis_tools.useful_functions import sort_dictionary_values\n",
        "sorted_dictionary = sort_dictionary_values(rdc_R_values)\n",
        "print(\"Ordered by R value (lower is better).\\n\\\n",
        "      Ensemble   R_value\")\n",
        "for key,value in sorted_dictionary.items():\n",
        "  print(f\"\\t{key.split('_')[0]}\\t {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IhSYRB5aBjXa"
      },
      "outputs": [],
      "source": [
        "#@title Energy Minimize an Ensemble\n",
        "options = [int(key.split('_')[0]) for key in sorted_dictionary.keys()]\n",
        "\n",
        "#@markdown Pick an ensemble to minimize based on the RDC fittings with low R values.\n",
        "#@markdown Execute the above cell and enter a number above from the Ensemble column.\n",
        "ensemble_to_minimize = 1 #@param {type:\"number\"}\n",
        "#@markdown This is just to improve the side chain conformations that were modeled into the structures.\n",
        "\n",
        "\n",
        "\n",
        "if ensemble_to_minimize in options:\n",
        "  \n",
        "  # restrain the backbone and minmize the side chain conformations\n",
        "  minimized_folder = f'minimized_cluster_{ensemble_to_minimize}'\n",
        "  if os.path.exists(minimized_folder):\n",
        "    pass\n",
        "  else:\n",
        "    os.makedirs(minimized_folder)\n",
        "\n",
        "  input_folder = f'all_atom_cluster_{ensemble_to_minimize}'\n",
        "  files_to_minimize = [f'{input_folder}/aa_centroid_{i+1}.pdb' for i in range(len(os.listdir(input_folder)))]\n",
        "  for j, pdb_file in enumerate(files_to_minimize):\n",
        "    print(f'Minimizing {pdb_file}.')\n",
        "    minimize_sidechains(f'{minimized_folder}/em_centroid_{j+1}.pdb', pdb_file)\n",
        "else:\n",
        "  print(f'Please choose an option between 1 and your maximum ensemble size of {len(options)}')\n",
        "\n",
        "!zip -FSr {minimized_folder}.zip {minimized_folder} &> /dev/null\n",
        "files.download(f\"{minimized_folder}.zip\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ColabOpenAWSEM.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}